# -*- coding: utf-8 -*-
"""proje1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BIMyPiBayLhLUpuQ6wQHmQD3gC5vUJuh

Son düzenlemeler yapılacak, epoch ve dropout değerleri optimize edilecek.
veriseti denk gelirse yas ve cinsiyet türevlerine bakılacak.
"""

import pandas as pd
import os

from google.colab import drive
drive.mount('/content/drive')

#!ls

"""Kaggle Config dizini ortama tanımlandı. Amaç bilgisayara indirmeden verisetini colab da kullanmak.

%cd ile input dizini içindeyim.
"""

os.environ['KAGGLE_CONFIG_DIR']= "/content/drive/MyDrive/Colab_Notebooks/input"

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/Colab_Notebooks/input"

!pwd

!kaggle datasets download -d deadskull7/fer2013

!kaggle kernels pull oykuer/emotion-detection-using-cnn

#!ls

!unzip \*.zip && rm *.zip

#!ls

#ilk 5 eğitim içeriğini gördüm.
data=pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/input/fer2013.csv')
print("Number of Labels:", data.emotion.max() + 1)
pd.set_option('max_colwidth',100)
data.head(5)

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from tensorflow import keras as ks
import numpy as np
import pandas as pd

import keras
from keras.models import Sequential, Model, model_from_json
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,BatchNormalization
from keras.layers import Dense, Activation, Dropout, Flatten
from keras.utils import np_utils
from keras.preprocessing import image
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from matplotlib import pyplot as plt
# %matplotlib inline

from keras.callbacks import ModelCheckpoint

model = ks.Sequential([
    ks.layers.LSTM(units=1, input_shape=(5, 1))
])

data["Usage"].value_counts()

np.unique(data["Usage"].values.ravel()) 

print('Eğitim verisetindeki örnek sayısı: %d'%(len(data[data.Usage == "Training"])))

train_data = data[data.Usage == "Training"]

train_pixels = train_data.pixels.str.split(" ").tolist() 
print(len(train_pixels))
train_pixels = pd.DataFrame(train_pixels, dtype=int)
train_images = train_pixels.values
train_images = train_images.astype(np.float64)

print(train_images)
print(train_images.shape)

def show(img, label="None"):
    show_image = img.reshape(48,48)
    plt.axis('off')
    plt.title(label)
    plt.imshow(show_image, cmap='gray')

#dict ve duygu_siniflari = ["Anger", "Disgust", "Fear", "Happy", "Neutral", "Sadness", "Surprise"]
labels = {
    0: "Angry",
    1: "Disgust",
    2: "Fear",
    3: "Happy",
    4: "Neutral",
    5: "Sad",
    6: "Surprise"
}

label_index = train_data.emotion
index = label_index[30]
label = labels[index]
show(train_images[30], label)

label_index = train_data.emotion
index = label_index[49]
label = labels[index]
show(train_images[49], label)

label_index = train_data.emotion
index = label_index[28705]
label = labels[index]
show(train_images[28705], label)

train_labels_flat = train_data["emotion"].values.ravel()
train_labels_count = np.unique(train_labels_flat).shape[0]
print('Farklı yüz ifadelerinin (duygu durumları) adedi: %d'%train_labels_count)

def dense_to_one_hot(labels_dense, num_classes):
    num_labels = labels_dense.shape[0]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1
    return labels_one_hot

x_train = dense_to_one_hot(train_labels_flat, train_labels_count)
x_train = x_train.astype(np.uint8)

print(x_train.shape)

y_train = dense_to_one_hot(train_labels_flat, train_labels_count)
y_train = y_train.astype(np.uint8)

print(y_train.shape)

np.unique(data["Usage"].values.ravel()) 

print('Test verisetindeki örnek sayısı: %d'%(len(data[data.Usage == "PublicTest"])))

"""float ile float64 arasındaki fark?
intleri düzenleyeyim mi?
"""

test_data = data[data.Usage == "PublicTest"] 
test_pixels = test_data.pixels.str.split(" ").tolist() 

test_pixels = pd.DataFrame(test_pixels, dtype=int)
test_images = test_pixels.values
test_images = test_images.astype(np.float64)

print(test_images.shape)

test_label_index = test_data["emotion"].values
index = test_label_index[0]
label = labels[index]
show(test_images[0], label)

test_label_index = test_data["emotion"].values
index = test_label_index[5]
label = labels[index]
show(test_images[5], label)

test_label_index = test_data["emotion"].values
index = test_label_index[3588]
label = labels[index]
show(test_images[3588], label)

test_labels_flat = test_data["emotion"].values.ravel()
test_labels_count = np.unique(test_labels_flat).shape[0]

y_test = dense_to_one_hot(test_labels_flat, test_labels_count)
y_test = y_test.astype(np.uint8)


print(y_test.shape)

plt.figure(0, figsize=(9,6))
for i in range(1,13):
    plt.subplot(3,4,i)
    plt.axis('off')
    image = test_images[i].reshape(48,48)
    plt.imshow(image, cmap="gray")

plt.tight_layout()
plt.show()

model=Sequential()

model.add(Conv2D(64, 3, data_format="channels_last", kernel_initializer="he_normal", input_shape=(48, 48, 1)))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(64, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Dropout(0.2))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Dropout(0.2))

#
model.add(Conv2D(128, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
#
model.add(Conv2D(256, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Flatten())
model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(Dropout(0.2))

model.add(Dense(7))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

"""# Bu görüntülerin çıktısını sadece duygu durumu olarak değil de cinsiyet ve yaşı da ekleyebilir miyim? Yoksa ek veriseti mi kullanayım?"""

x_train = train_images.reshape(-1, 48, 48, 1)
x_test = test_images.reshape(-1, 48, 48, 1)

print("Train:", x_train.shape)
print("Test:", x_test.shape)

print("Train:", y_train.shape)
print("Test:", y_test.shape)

checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint', verbose=1, save_best_only=True)

epochs = 22
#25
batchSize = 128

# modeli çalıştır
hist = model.fit(x_train, y_train,
                 epochs=epochs,
                 shuffle=True,
                 batch_size=batchSize, 
                 validation_data=(x_test, y_test),
                 callbacks=[checkpointer], verbose=2)

# save model to json
#root='/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint'

model_json = model.to_json()
with open("/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/saved_model.pb", "w") as json_file:
  json_file.write(model_json)

model.save("/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/variables/face_model2.h5")

# Plot training & validation accuracy values
plt.figure(figsize=(14,3))
plt.subplot(1, 2, 1)
plt.suptitle('Eğitim Başarısı', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.plot(hist.history['loss'], color='b', label='Training Loss')
plt.plot(hist.history['val_loss'], color='r', label='Validation Loss')
plt.legend(loc='upper right')

plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.plot(hist.history['accuracy'], color='b', label='Training Accuracy')
plt.plot(hist.history['val_accuracy'], color='r', label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

test = data[["emotion", "pixels"]][data["Usage"] == "PrivateTest"]
test["pixels"] = test["pixels"].apply(lambda im: np.fromstring(im, sep=' '))
test.head()

x_test_private = np.vstack(test["pixels"].values)
y_test_private = np.array(test["emotion"])

x_test_private = x_test_private.reshape(-1, 48, 48, 1)
y_test_private = np_utils.to_categorical(y_test_private)

x_test_private.shape, y_test_private.shape

score = model.evaluate(x_test_private, y_test_private, verbose=0)
print("PrivateTest üzerinde doğruluk başarımı:", score)

# Commented out IPython magic to ensure Python compatibility.
from keras.models import load_model
from PIL import Image
from keras.preprocessing import image

import numpy as np
import matplotlib.pyplot as plt
import h5py
import scipy

from scipy import ndimage
#from lr_utils import load_dataset

# %matplotlib inline

#root='/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint'
data = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/data/fer2013.csv')
data.shape

# import h5py as h5
# import scipy.io
# import time 

# time.sleep(5)
# data='/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5'
# #f=h5.File(data, 'r')
# f=model.load
# f = scipy.io.loadmat('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5')

# import scipy.io as sio
# sio.savemat('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5', mdict, appendmat=True, format='5', long_field_names=False, do_compression=False, oned_as='row')
# scipy.io.savemat('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5',long_field_names=True)
# data = sio.loadmat('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5', verify_compressed_data_integrity=False)

# # data = sio.loadmat('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5')
# save('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5', 'data', '-v6');

# en iyi ağırlıkları yükle

#model.load_weights('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5')
loaded = keras.models.load_model("/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/variables/face_model2.h5")
#model_best = load_model('/content/drive/MyDrive/Colab_Notebooks/input/ModelCheckpoint/face_model.h5')

test_image=x_test_private[15]

custom = model.predict(test_image.reshape(-1, 48, 48, 1))

#1
objects = ('kızgın', 'nefret', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')
y_pos = np.arange(len(objects))
    
plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')
plt.xticks(y_pos, objects)
plt.ylabel('yüzde')
plt.title('duygu')
plt.show()

#2
x = np.array([48, 48], 'float32')
#x = x.reshape([48, 48);
plt.axis('off')
plt.gray()
plt.imshow(test_image.reshape(48,48))

plt.show()

# Kendi örneklerimizle test işlem adımları

import cv2

x_test_private = test_images[5].reshape(-1, 48, 48, 1)

#!ls '/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images'

image_path = "/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/brando.png"
import keras.utils as image
from tensorflow.keras.utils import load_img

test_image_original = image.load_img(image_path) # orjinal renkli görüntü

test_image = image.load_img(image_path, target_size=(48, 48), grayscale=True)
test_data = image.img_to_array(test_image)

test_data = np.expand_dims(test_data, axis=0)
test_data = np.vstack([test_data])

results = model.predict(test_data, batch_size=1)
results

from google.colab.patches import cv2_imshow

# Commented out IPython magic to ensure Python compatibility.
from tensorflow.keras.preprocessing import image

test_image="/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/brando.png"
img = image.load_img(test_image, target_size=(48, 48))
img_array = image.img_to_array(img)

custom = model.predict(img_array.reshape(-1,48,48,1))

#1
objects = ('kızgın', 'nefret', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')
y_pos = np.arange(len(objects))
    
plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')
plt.xticks(y_pos, objects)
plt.ylabel('yüzde')
plt.title('duygu')
plt.show()

#2
x = np.array([48, 48], 'float32')
#x = x.reshape([48, 48]);
plt.axis('off')
plt.gray()

import matplotlib.image as mpimg 
from matplotlib.pyplot import imshow
# %matplotlib inline
testim = mpimg.imread('/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/brando.png')
imshow(testim)


plt.show("/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/brando.png")

# #1
# objects = ('kızgın', 'nefret', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')
# y_pos = np.arange(len(objects))
    
# plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')
# plt.xticks(y_pos, objects)
# plt.ylabel('yüzde')
# plt.title('duygu')
# plt.show()

# #2
# x = np.array([48, 48], 'float32')
# #x = x.reshape([48, 48]);
# plt.axis('off')
# plt.gray()

# plt.show()

# Commented out IPython magic to ensure Python compatibility.
test_image="/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/kemal_sunal2.jpg"
img = image.load_img(test_image, target_size=(48, 48))
img_array = image.img_to_array(img)

custom = model.predict(img_array.reshape(-1,48,48,1))

#1
objects = ('kızgın', 'nefret', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')
y_pos = np.arange(len(objects))
    
plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')
plt.xticks(y_pos, objects)
plt.ylabel('yüzde')
plt.title('duygu')
plt.show()

#2
x = np.array([48, 48], 'float32')
#x = x.reshape([48, 48]);
plt.axis('off')
plt.gray()

import matplotlib.image as mpimg 
from matplotlib.pyplot import imshow
# %matplotlib inline
testim = mpimg.imread('/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/kemal_sunal2.jpg')
imshow(testim)


plt.show("/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/kemal_sunal2.jpg")

# Commented out IPython magic to ensure Python compatibility.
test_image="/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/javierbardem.jpg"
img = image.load_img(test_image, target_size=(48, 48))
img_array = image.img_to_array(img)

custom = model.predict(img_array.reshape(-1,48,48,1))

#1
objects = ('kızgın', 'nefret', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')
y_pos = np.arange(len(objects))
    
plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')
plt.xticks(y_pos, objects)
plt.ylabel('yüzde')
plt.title('duygu')
plt.show()

#2
x = np.array([48, 48], 'float32')
#x = x.reshape([48, 48]);
plt.axis('off')
plt.gray()

import matplotlib.image as mpimg 
from matplotlib.pyplot import imshow
# %matplotlib inline
testim = mpimg.imread('/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/javierbardem.jpg')
imshow(testim)


plt.show("/content/drive/MyDrive/Udemy_DerinOgrenmeyeGiris/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/javierbardem.jpg")

